docker network create app-network

mvn clean package -D skipTests

docker build . -t productsearch

docker run -d -p 8080:8080 --network app-network productsearch


docker run -d --name elasticsearch-dev \
  --network app-network \
  -e "discovery.type=single-node" \
  -e ES_JAVA_OPTS="-Xms4g -Xmx4g" \
  -e "xpack.security.enabled=false" \
  -p 9200:9200 \
  --restart unless-stopped \
  docker.elastic.co/elasticsearch/elasticsearch:8.12.2

docker run -d --name kibana-dev \
  --network app-network \
  -e ELASTICSEARCH_HOSTS=http://elasticsearch-dev:9200 \
  -p 5601:5601 \
  --restart unless-stopped \
  docker.elastic.co/kibana/kibana:8.12.2


docker run -d --name mongo-dev \
  --network app-network \
  -p 27017:27017 \
  --restart unless-stopped \
  mongo

  docker exec -it mongo-dev mongosh

docker run -d --name kafka-kraft \
  --network app-network \
  -p 29092:29092 \
  -p 9094:9094 \
  -e KAFKA_ENABLE_KRAFT=yes \
  -e ALLOW_PLAINTEXT_LISTENER=yes \
  -e KAFKA_CFG_NODE_ID=1 \
  -e KAFKA_CFG_PROCESS_ROLES=broker,controller \
  -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER \
  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka-kraft:9093 \
  -e KAFKA_CFG_LISTENERS="INTERNAL://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093,EXTERNAL://0.0.0.0:9094" \
  -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP="INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT" \
  -e KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL \
  -e KAFKA_CFG_ADVERTISED_LISTENERS="INTERNAL://kafka-kraft:29092,EXTERNAL://localhost:9094" \
  --restart unless-stopped \
  bitnami/kafka:latest

  


    docker exec -it kafka-kraft bash  
    kafka-topics.sh --bootstrap-server kafka-kraft:29092 --list
    kafka-console-consumer.sh --bootstrap-server kafka-kraft:29092 --topic product-topic -from-beginning



docker run -d --name kafka-connect \
  --network app-network \
  -p 8083:8083 \
  -e CONNECT_BOOTSTRAP_SERVERS=kafka-kraft:29092 \
  -e CONNECT_GROUP_ID="connect-cluster" \
  -e CONNECT_CONFIG_STORAGE_TOPIC="connect-configs" \
  -e CONNECT_OFFSET_STORAGE_TOPIC="connect-offsets" \
  -e CONNECT_STATUS_STORAGE_TOPIC="connect-status" \
  -e CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1 \
  -e CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1 \
  -e CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1 \
  -e CONNECT_KEY_CONVERTER="org.apache.kafka.connect.storage.StringConverter" \
  -e CONNECT_VALUE_CONVERTER="org.apache.kafka.connect.json.JsonConverter" \
  -e CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE="false" \
  -e CONNECT_REST_ADVERTISED_HOST_NAME=kafka-connect \
  -e CONNECT_PLUGIN_PATH="/usr/share/confluent-hub-components" \
    confluentinc/cp-kafka-connect:7.5.0   bash -c "confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:14.0.0 && /etc/confluent/docker/run"

Adding connector
curl -X POST http://localhost:8083/connectors \
  -H 'Content-Type: application/json' \
  -d '{
    "name": "elasticsearch-sink",
    "config": {
      "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
      "tasks.max": "1",
      "topics": "product-topic",
      "connection.url": "http://elasticsearch-dev:9200",
      "type.name": "_doc",
      "key.ignore": "true",
      "schema.ignore": "true"
    }
  }'

Deleting connector
curl -X DELETE http://localhost:8083/connectors/elasticsearch-sink

docker run -p 8080:8080 --name productsearch productsearch

docker container prune -f

